{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eksperimen data Census\n",
    " \n",
    "\n",
    "Oleh : Bervianto Leo P - 13514047 dan Muhammad Reifiza - 13514103"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fungsi _Plot Confusion Matrix_\n",
    "\n",
    "Fungsi ini digunakan nanti, untuk memplot _confusion matrix_ dalam bentuk grafik.\n",
    "\n",
    "Diambil dari http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import numpy as np\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mempersiapkan data dari csv\n",
    "Data census harus ada di dalam folder yang sama dengan _script_ ini dijalankan. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import pandas\n",
    "\n",
    "namesCensus = ['age', 'workclass', 'fnlwgt', 'education', 'education-num', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'hours-per-week', 'native-country', 'class']\n",
    "\n",
    "census_train_raw = pandas.read_csv(\"CencusIncome.data.txt\", index_col=False, header = 0, names=namesCensus)\n",
    "census_train = pandas.DataFrame(census_train_raw)\n",
    "\n",
    "census_test_raw = pandas.read_csv(\"CencusIncome.test.txt\", index_col=False, header = 0, names=namesCensus)\n",
    "census_test = pandas.DataFrame(census_test_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preproses data\n",
    "Karena nilai data semuanya dalam bentuk string, kalau langsung dimasukkan akan menyebabkan sklearn tree dan seaborn terbingung-bingung. Oleh karena itu, data mesti dipreproses dulu dengan meng-_encode_ nya nilai datanya menjadi float."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "encoder = preprocessing.LabelEncoder()\n",
    "for col in [\"workclass\", \"education\", \"marital-status\", \"occupation\", \"relationship\", \"race\", \"sex\", \"native-country\", \"class\"]:\n",
    "    census_train[col] = encoder.fit_transform(census_train[col])  \n",
    "    census_test[col] = encoder.fit_transform(census_test[col])  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisasi data\n",
    "\n",
    "Data divisualisasikan dengan menggunakan _library_ seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn\n",
    "seaborn.set(color_codes=True)\n",
    "g = seaborn.PairGrid(census_train, hue=\"class\")\n",
    "g.map_diag(plt.hist)\n",
    "g.map_offdiag(plt.scatter)\n",
    "g.add_legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Membuat _Classifier Decision Tree dan ANN.\n",
    "\n",
    "Skema _Full Training_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "census_train_train = census_train.drop(\"class\", axis=1)\n",
    "census_train_classes = census_train.iloc[:,-1]\n",
    "\n",
    "census_test_data = census_test.drop(\"class\", axis=1)\n",
    "census_test_classes = census_test.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Terbaik 1\n",
    "\n",
    "Ini adalah model terbaik "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tree params 1\n",
    "myMaxDepth = 5\n",
    "\n",
    "#ANN params 1\n",
    "myAlpha = 1e-6\n",
    "myhiddenLayer = (10,10)\n",
    "myRandomState = 1 \n",
    "\n",
    "myDTLCrossFold = 10\n",
    "myANNCrossFold = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "dtl = tree.DecisionTreeClassifier(criterion = myCriterion,presort = myPresort, max_depth = myMaxDepth)\n",
    "dtl.fit(census_train_train, census_train_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "ann = MLPClassifier(alpha=myAlpha, hidden_layer_sizes=myhiddenLayer, random_state=myRandomState)\n",
    "ann.fit(census_train_train, census_train_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ukuran Kinerja Model 1\n",
    "\n",
    "Ukuran kinerja yang kami gunakan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(dtl, census_test_data, census_test_classes, cv=myDTLCrossFold)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(ann, census_test_data, census_test_classes, cv=myANNCrossFold)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Terbaik 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tree params 1\n",
    "myMaxDepth = 4\n",
    "\n",
    "#ANN params 1\n",
    "myAlpha = 1e-6\n",
    "myhiddenLayer = (10,3)\n",
    "myRandomState = 1 \n",
    "\n",
    "myDTLCrossFold = 10\n",
    "myANNCrossFold = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtl = tree.DecisionTreeClassifier(criterion = myCriterion,presort = myPresort, max_depth = myMaxDepth)\n",
    "dtl.fit(census_train_train, census_train_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann = MLPClassifier(alpha=myAlpha, hidden_layer_sizes=myhiddenLayer, random_state=myRandomState)\n",
    "ann.fit(census_train_train, census_train_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ukuran Kinerja Model 2\n",
    "\n",
    "Ukuran kinerja yang kami gunakan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(dtl, census_test_data, census_test_classes, cv=myDTLCrossFold)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(ann, census_test_data, census_test_classes, cv=myANNCrossFold)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kesimpulan\n",
    "\n",
    "Tidak ada penanganan khusus terhadap data. \n",
    "\n",
    "Skenario yang kami gunakan adalah mencoba membandingkan kinerja model menggunakan parameter yang diubah satu per satu dengan parameter yang ditemukan paling baik. Model yang paling pertama paling baik dianggap model dengan parameter default. Ketika kami mencoba sebuah parameter tidak berpengaruh, maka kami langsung mengabaikan parameter tersebut dan berganti dengan parameter lain.\n",
    "\n",
    "2 Konfigurasi model terbaik dari hasil eksperimen bisa dilihat di atas.\n",
    "\n",
    "Kami menemukan bahwa hasil kinerja model dtl konsisten, namun model ann kami tidak menemukan konsistensinya. Untuk dtl, model terbaik memiliki max depth yang lebih rendah daripada model terbaik kedua. Bisa dibilang untuk dtl, model terbaik lebih general daripada model terbaik kedua, namun untuk ann, model terbaik tidak lebih general daripada model terbaik kedua."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
